from datetime import datetime
import json
import random
import re
from collections import Counter
from itertools import combinations
import urllib.parse
import urllib.request

import pandas as pd
import numpy as np


import matplotlib.pyplot as plt
from matplotlib.widgets import Slider

import seaborn as sns
import plotly.express as px
import altair as alt

from wordcloud import WordCloud, STOPWORDS
from PIL import Image

import networkx as nx

import streamlit as st


st.set_page_config(
    page_title="ë°ì´í„° ì‹œê°í™” ê¸°ë§ê³ ì‚¬",
    page_icon="ğŸ“Œ",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        "Get Help": "https://www.streamlit.io/help",
        "Report a bug": "https://streamlit.io/bug",
        "About": "ì „íƒœí™˜ - Hello Streamlit ì•±ì…ë‹ˆë‹¤."
    }
)


st.title('â–ªï¸C221061 ì „íƒœí™˜ ')
st.write("""# ë°ì´í„° ì‹œê°í™” ê¸°ë§ê³ ì‚¬ í”„ë¡œì íŠ¸""")
st.write("""### í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.""")


keyword_list = ["Golden ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim", "KíŒ ë°ëª¬ í—Œí„°ìŠ¤_date", "Takedown ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim", "í†µí•© ë°ì´í„°"]
selected_keyword = st.selectbox("í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", keyword_list)
st.header(f"ì„ íƒëœ í‚¤ì›Œë“œ: {selected_keyword}")


#ì„ íƒí•œ í‚¤ì›Œë“œì— ë”°ë¼ ì´ë¯¸ì§€ ì¶œë ¥
if selected_keyword == "Golden ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim":
    st.write("# wordCloud ì‹œê°í™” ê²°ê³¼")
    st.image("Golden ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim word Cloud ì‹œê°í™”.png", caption="Golden ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim Word Cloud", use_container_width=True)
    st.write("# Networkx ì‹œê°í™” ê²°ê³¼")
    st.image("Golden ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”.png", caption="Golden ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim Network Visualization", use_container_width=True)
    st.write("# Seaborn íˆìŠ¤í† ê·¸ë¨ ì‹œê°í™” ê²°ê³¼")
    st.image("Golden ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_simí‚¤ì›Œë“œ_íˆìŠ¤í† ê·¸ë¨.png", caption="Golden ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim Keyword Histogram", use_container_width=True)
    st.write("# ê´€ë ¨ ë‰´ìŠ¤ ì‚¬ì§„")
    st.image("Golden ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_ë‰´ìŠ¤.png", caption="Golden ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim ê´€ë ¨ ë‰´ìŠ¤", use_container_width=True)
    # ì„¤ëª… ì¶”ê°€
elif selected_keyword == "KíŒ ë°ëª¬ í—Œí„°ìŠ¤_date":
    st.write("# wordCloud ì‹œê°í™” ê²°ê³¼")
    st.image("KíŒ ë°ëª¬ í—Œí„°ìŠ¤_date word Cloud ì‹œê°í™”.png", caption="KíŒ ë°ëª¬ í—Œí„°ìŠ¤_date Word Cloud", use_container_width=True)
    st.write("# Networkx ì‹œê°í™” ê²°ê³¼")
    st.image("KíŒ ë°ëª¬ í—Œí„°ìŠ¤_date ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”.png", caption="KíŒ ë°ëª¬ í—Œí„°ìŠ¤_date Network Visualization", use_container_width=True)
    st.write("# Seaborn íˆìŠ¤í† ê·¸ë¨ ì‹œê°í™” ê²°ê³¼")
    st.image("KíŒ ë°ëª¬ í—Œí„°ìŠ¤_dateí‚¤ì›Œë“œ_íˆìŠ¤í† ê·¸ë¨.png", caption="KíŒ ë°ëª¬ í—Œí„°ìŠ¤_date Keyword Histogram", use_container_width=True)
    st.write("# ê´€ë ¨ ë‰´ìŠ¤ ì‚¬ì§„")
    st.image("KíŒ ë°ëª¬ í—Œí„°ìŠ¤_ë‰´ìŠ¤.png", caption   ="KíŒ ë°ëª¬ í—Œí„°ìŠ¤_date ê´€ë ¨ ë‰´ìŠ¤", use_container_width=True)
    # ì„¤ëª… ì¶”ê°€

elif selected_keyword == "Takedown ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim":
    st.write("# wordCloud ì‹œê°í™” ê²°ê³¼")
    st.image("Takedown ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim word Cloud ì‹œê°í™”.png", caption="Takedown ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim Word Cloud", use_container_width=True)
    st.write("# Networkx ì‹œê°í™” ê²°ê³¼")
    st.image("Takedown ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”.png", caption="Takedown ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim Network Visualization", use_container_width=True)
    st.write("# Seaborn íˆìŠ¤í† ê·¸ë¨ ì‹œê°í™” ê²°ê³¼")
    st.image("Takedown ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_simí‚¤ì›Œë“œ_íˆìŠ¤í† ê·¸ë¨.png", caption="Takedown ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim Keyword Histogram", use_container_width=True)
    st.write("# ê´€ë ¨ ë‰´ìŠ¤ ì‚¬ì§„")
    st.image("Takedown ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_ë‰´ìŠ¤.png", caption="Takedown ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤_sim ê´€ë ¨ ë‰´ìŠ¤", use_container_width=True)
    # ì„¤ëª… ì¶”ê°€

elif selected_keyword == "í†µí•© ë°ì´í„°":
    st.write("# wordCloud ì‹œê°í™” ê²°ê³¼")
    st.image("í†µí•© ë°ì´í„° word Cloud ì‹œê°í™”.png", caption="í†µí•© ë°ì´í„° Word Cloud", use_container_width=True)
    st.write("# Networkx ì‹œê°í™” ê²°ê³¼")
    st.image("í†µí•© ë°ì´í„° ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”.png", caption="í†µí•© ë°ì´í„° Network Visualization", use_container_width=True)
    st.write("# Seaborn íˆìŠ¤í† ê·¸ë¨ ì‹œê°í™” ê²°ê³¼")
    st.image("í†µí•© ë°ì´í„°í‚¤ì›Œë“œ_íˆìŠ¤í† ê·¸ë¨.png", caption="í†µí•© ë°ì´í„° Keyword Histogram", use_container_width=True)
    # ì„¤ëª… ì¶”ê°€
else:
    st.write("ìœ íš¨í•˜ì§€ ì•Šì€ ì„ íƒì…ë‹ˆë‹¤.")

"""
---
---
# í†µí•© ë°ì´í„°í”„ë ˆì„ ë¶ˆëŸ¬ì˜¤ê¸°
"""

combined_df = pd.read_json('combined_df.json', encoding='utf-8')

# combined_df ì¶œë ¥
st.subheader("í†µí•© ë°ì´í„°í”„ë ˆì„ ë¯¸ë¦¬ë³´ê¸°")
st.dataframe(combined_df.head())

"""
---
"""
def edge_counts(token_list, n=2): 
    edge_list = []
    for nouns in token_list:
        if len(nouns) >= n :
            edge_list.extend(combinations(sorted(nouns),n))
    edge_counts = Counter(edge_list)
    return edge_counts

def counter_to_word_freq(counter):
    return {
        word_tuple[0]: freq
        for word_tuple, freq in counter.items()
    }

def draw_altair_bar_plot_with_slider(combined_df, file_name, top_k=15):

    # search_keyword ë³„ ë‹¨ì–´ ë¹ˆë„ ì§‘ê³„
    data = []
    for keyword in combined_df['search_keyword'].unique():
        subset_df = combined_df[combined_df['search_keyword'] == keyword]
        term_dict = counter_to_word_freq(edge_counts(subset_df["title_token"], 1))
        word_freq = dict(
            sorted(term_dict.items(), key=lambda x: x[1], reverse=True)[:top_k]
        )
        for word, freq in word_freq.items():
            data.append({
                'word': word,
                'search_keyword': keyword,
                'frequency': freq
            })

    df_altair = pd.DataFrame(data)

    # âœ… Altair v5 ë°©ì‹ selection
    selector = alt.selection_point(
        fields=['search_keyword'],
        bind=alt.binding_select(
            options=combined_df['search_keyword'].unique().tolist(),
            name='ê²€ìƒ‰ í‚¤ì›Œë“œ: '
        )
    )

    chart = (
        alt.Chart(df_altair)
        .mark_bar()
        .encode(
            x=alt.X('word:N', sort='-y', title='ë‹¨ì–´'),
            y=alt.Y('frequency:Q', title='ë¹ˆë„ìˆ˜'),
            color=alt.Color('word:N', legend=None)
        )
        .add_params(selector)
        .transform_filter(selector)
        .properties(
            width=800,
            height=400,
            title=file_name + " í‚¤ì›Œë“œ íˆìŠ¤í† ê·¸ë¨ (Altair)"
        )
    )
    st.altair_chart(chart, use_container_width=True)
    # ê·¸ë˜í”„ ì‹œê°í™”
    

# k ì„ íƒ ìœ„ì ¯ ë§Œë“¤ê¸°
st.write("### ìƒìœ„ kê°œ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
top_k = st.slider("ìƒìœ„ kê°œ ë‹¨ì–´ ì„ íƒ", min_value=5, max_value=30, value=15, step=1)

draw_altair_bar_plot_with_slider(combined_df, "í†µí•© ë°ì´í„°", top_k=top_k)

"""
# ê²°ê³¼ í•´ì„
---
#### ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤ì˜ ë…¸ë˜ 'Golden'ê³¼ 'Takedown'ì´ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ë§ì´ ì–¸ê¸‰ë˜ê³  ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#### Golden ì€ íŠ¹íˆ goldenGloveì˜ ìˆ˜ìƒ í›„ë³´ë¡œ ì˜¤ë¥´ë©° ë§ì€ ê¸°ì‚¬ê°€ ìŸì•„ì ¸ ë‚˜ì™”ê³ , 
#### Takedownì€ ë¹Œë³´ë“œ ì°¨íŠ¸ì—ì„œ ì¢‹ì€ ì„±ì ì„ ê±°ë‘ë©° ì—¬ëŸ¬ ê¸°ì‚¬ê°€ ì‘ì„±ëœ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.
#### ì´ëŸ¬í•œ ê¸°ì‚¬ë¥¼ ë³´ì•„ OST ê°€ ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤ì˜ ì¸ê¸°ì™€ ì„±ê³µì— ì¤‘ìš”í•œ ì—­í• ì„ í•œ ê²ƒìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#### ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤ì˜ í•´ì™¸ ë°˜ì‘ì€ ë„·í”Œë¦­ìŠ¤ì—ì„œ ì—´í’ì´ì—ˆë‹¤ëŠ” ê¸°ì‚¬ë¥¼ í†µí•´ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.
#### ë˜í•œ ë¦¬ë·°ë¡œ í•œêµ­ì˜ ë¬¸í™”ì— ëŒ€í•´ ì˜ ì•Œê²Œë˜ì—ˆë‹¤ëŠ” ë¦¬ë·°ê°€ ë§ìœ¼ë©°, ë‹¤ì–‘í•œ ê¸°ì—…(ë†ì‹¬ ë“±)ê³¼ì˜ í˜‘ì—… ê´€ë ¨ëœ ê¸°ì‚¬ë¥¼ ë°œê²¬ í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.
#### ì´ë¥¼ í†µí•´ ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤ê°€ ë‹¨ìˆœí•œ ì• ë‹ˆë©”ì´ì…˜ì„ ë„˜ì–´ í•œêµ­ ë¬¸í™”ì™€ ì‚°ì—… ì „ë°˜ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

"""

